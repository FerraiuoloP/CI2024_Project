{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from icecream import ic\n",
    "import cProfile \n",
    "import time\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'divide': 'ignore', 'over': 'ignore', 'under': 'ignore', 'invalid': 'ignore'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#warning settings\n",
    "np.seterr(all=\"ignore\") #ignore np warnings, the output will be nan or inf and will be handled correctly in the code. (using np.errstate slows down the code)\n",
    "# warnings.filterwarnings(\"ignore\", category=RuntimeWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "TRAIN_TEST_RATIO=0.8\n",
    "PROBLEM_NUMBER=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the training and testing data\n",
    "def normalize_data(x, y, feature_range=(0, 1)):\n",
    "    \"\"\"\n",
    "    Normalize input (x) and output (y) data using min-max normalization.\n",
    "\n",
    "    Parameters:\n",
    "        x: np.ndarray, input data (variables, samples).\n",
    "        y: np.ndarray, output data (samples).\n",
    "        feature_range: tuple (min, max), range for normalization.\n",
    "\n",
    "    Returns:\n",
    "        x_norm: Min-max normalized input data.\n",
    "        y_norm: Min-max normalized output data.\n",
    "        x_stats: Dict containing min and max for x.\n",
    "        y_stats: Dict containing min and max for y.\n",
    "    \"\"\"\n",
    "    x_min = np.min(x, axis=1, keepdims=True)\n",
    "    x_max = np.max(x, axis=1, keepdims=True)\n",
    "    x_norm = (x - x_min) / (x_max - x_min) * (feature_range[1] - feature_range[0]) + feature_range[0]\n",
    "\n",
    "    y_min = np.min(y)\n",
    "    y_max = np.max(y)\n",
    "    y_norm = (y - y_min) / (y_max - y_min) * (feature_range[1] - feature_range[0]) + feature_range[0]\n",
    "\n",
    "    x_stats = {\"min\": x_min, \"max\": x_max}\n",
    "    y_stats = {\"min\": y_min, \"max\": y_max}\n",
    "\n",
    "    return x_norm, y_norm, x_stats, y_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading and Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem number: 1, variables: 1, train size: 400, test size: 100\n",
      "Training data: x shape (1, 400), y shape (400,)\n",
      "Testing data: x shape (1, 100), y shape (100,)\n"
     ]
    }
   ],
   "source": [
    "# Load problem data with context manager protocol\n",
    "with np.load(f'data/problem_{PROBLEM_NUMBER}.npz') as problem:\n",
    "    x_1 = problem['x']\n",
    "    y_1 = problem['y']\n",
    "\n",
    "# Shuffle the data\n",
    "permutation = np.random.permutation(len(y_1))\n",
    "x_1 = x_1[:, permutation]\n",
    "y_1 = y_1[permutation]\n",
    "\n",
    "# Determine train test split sizes\n",
    "problem_len=len(y_1)\n",
    "train_size=int(TRAIN_TEST_RATIO*problem_len)\n",
    "\n",
    "# Split data\n",
    "x_train = x_1[:, :train_size]\n",
    "y_train = y_1[:train_size]\n",
    "\n",
    "x_test = x_1[:, train_size:]\n",
    "y_test = y_1[train_size:]\n",
    "\n",
    "# Normalize training and testing data\n",
    "x_train_norm, y_train_norm, x_stats, y_stats = normalize_data(x_train, y_train)\n",
    "x_test_norm, y_test_norm, _, _ = normalize_data(x_test, y_test)\n",
    "\n",
    "# To view the npz file, run python -m npzviewer \n",
    "# Print dataset information\n",
    "print(f\"Problem number: {PROBLEM_NUMBER}, variables: {x_1.shape[0]}, train size: {train_size}, test size: {problem_len-train_size}\")\n",
    "print(f\"Training data: x shape {x_train_norm.shape}, y shape {y_train_norm.shape}\")\n",
    "print(f\"Testing data: x shape {x_test_norm.shape}, y shape {y_test_norm.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numpy functions definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "unary_ops = [\n",
    "    np.negative,\n",
    "    np.abs,\n",
    "    np.sqrt,\n",
    "    np.exp,\n",
    "    np.log,\n",
    "    np.sin,\n",
    "    np.cos,\n",
    "    np.tan,\n",
    "    # np.arcsin,\n",
    "    # np.arccos,\n",
    "    # np.arctan,\n",
    "    # np.ceil,\n",
    "    # np.floor\n",
    "]\n",
    "\n",
    "binary_ops = [\n",
    "    np.add,\n",
    "    np.subtract,\n",
    "    np.multiply,\n",
    "    np.divide,\n",
    "    np.power,\n",
    "    # np.maximum,\n",
    "    # np.minimum,\n",
    "    # np.mod\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Symbolic Regression Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tree import Tree\n",
    "\n",
    "class SymbolicRegression:\n",
    "    def __init__(self, population_size, max_generations, mutation_rate, elitism_size, grow_full_ratio):\n",
    "        self.population_size = population_size\n",
    "        self.max_generations = max_generations\n",
    "        self.mutation_rate = mutation_rate\n",
    "        self.elitism_size = elitism_size\n",
    "        self.grow_full_ratio = grow_full_ratio\n",
    "\n",
    "        self.unary_ops = unary_ops\n",
    "        self.binary_ops = binary_ops\n",
    "        self.best_fitness_history = []\n",
    "        \n",
    "        self.population = np.array([\n",
    "            Tree(\"grow\") if i < int(population_size * self.grow_full_ratio) else Tree(\"full\")\n",
    "            for i in range(population_size)\n",
    "        ])\n",
    "\n",
    "    # Parents selection methods\n",
    "    def select_parents_fitness_proportional(self, n_elems=2, epsilon=1e-10):\n",
    "        \"\"\"\n",
    "        Individuals with lower fitness have an higher probability to be selected.\n",
    "        Premature convergence if few individuals have significantly better fitness than others.\n",
    "        \"\"\"\n",
    "        fitnesses = [tree.fitness for tree in self.population]\n",
    "        inverted_fitnesses = [1 / (fitness + epsilon) for fitness in fitnesses]  # avoid division by zero\n",
    "        probabilities = inverted_fitnesses / sum(inverted_fitnesses)\n",
    "        parent1, parent2 = np.random.choice(self.population, size=n_elems, p=probabilities, replace=False)\n",
    "        return parent1, parent2\n",
    "    \n",
    "    def select_parents_lexicase(self):  # TODO: implement this\n",
    "        pass\n",
    "\n",
    "    def select_parents_rank_based(self, n_elems=2):\n",
    "        \"\"\"\n",
    "        Rank-based selection method.\n",
    "        Assigns probabilities based on inversed ranks instead of absolute fitness values.\n",
    "        \"\"\"\n",
    "        fitnesses = np.array([tree.fitness for tree in self.population])\n",
    "        ranks = np.argsort(fitnesses)\n",
    "        inversed_ranks = len(fitnesses) - ranks\n",
    "        probabilities = inversed_ranks / np.sum(inversed_ranks)\n",
    "        return np.random.choice(self.population, n_elems, p=probabilities, replace=False)\n",
    "    \n",
    "    def select_parents_tournament(self):\n",
    "        tournament_size = 7\n",
    "        tournament = list(np.random.choice(self.population, tournament_size, replace=False))\n",
    "        tournament.sort(key=lambda x: x.fitness)\n",
    "        return tournament[0], tournament[1]\n",
    "    \n",
    "    def select_parents(self):\n",
    "        return self.select_parents_rank_based()\n",
    "\n",
    "    # Mutation methods\n",
    "    def mutate(self, tree):\n",
    "        if np.random.rand() < 0.5:\n",
    "            tree.mutate_subtree()\n",
    "        else:\n",
    "            tree.mutate_single_node()\n",
    "\n",
    "    # Offsprings generation via mutation and crossover\n",
    "    def offspring_generation(self):\n",
    "        new_population = np.array([])\n",
    "\n",
    "        # Elitism   \n",
    "        elite_individuals = self.population[:self.elitism_size]\n",
    "        new_population = elite_individuals\n",
    "\n",
    "        # Main loop\n",
    "        while len(new_population) < self.population_size: #//2:\n",
    "            parent1, parent2 = self.select_parents()\n",
    "\n",
    "            # generate offsprings (one in mutation, two in crossover)\n",
    "            offsprings = np.array([])\n",
    "\n",
    "            if(np.random.rand() < self.mutation_rate):\n",
    "                parent_clone = parent1.copy_tree()\n",
    "                self.mutate(parent_clone)\n",
    "                Tree.collapse_branch(parent_clone.root)\n",
    "                parent_clone.compute_fitness()\n",
    "                # if(parent_clone not in new_population):\n",
    "                offsprings = np.append(offsprings, [parent_clone])\n",
    "\n",
    "            else:    \n",
    "                offspring1, offspring2 = Tree.crossover(parent1, parent2)\n",
    "                if(offspring1 is not None or offspring2 is not None):\n",
    "                    Tree.collapse_branch(offspring1.root)\n",
    "                    Tree.collapse_branch(offspring2.root)\n",
    "                \n",
    "                    # self.mutate(offspring1)\n",
    "                    # self.mutate(offspring2)\n",
    "\n",
    "                    #Trying stuff\n",
    "                    # offspring1.compute_fitness()\n",
    "                    # offspring2.compute_fitness()\n",
    "                    # tmp_fitnesses=[tree.fitness for tree in new_population]\n",
    "                    # if offspring1.fitness not in tmp_fitnesses:\n",
    "                    #     offsprings.append(offspring1)\n",
    "                    # if offspring2.fitness not in tmp_fitnesses:\n",
    "                    #     offsprings.append(offspring2)\n",
    "                    \n",
    "                    offspring1.compute_fitness()\n",
    "                    offspring2.compute_fitness()\n",
    "\n",
    "                    #if osspring1 is not alredy in population, already defined the eq as the fitness comparison\n",
    "                    # if offspring1 not in new_population:\n",
    "                    #     offsprings = np.append(offsprings, [offspring1])\n",
    "                    # if offspring2 not in new_population:\n",
    "                    #     offsprings = np.append(offsprings, [offspring2])\n",
    "\n",
    "                    offsprings = np.append(offsprings, [offspring1, offspring2])\n",
    "\n",
    "            new_population = np.concatenate((new_population, offsprings))\n",
    "                \n",
    "        return new_population\n",
    "    \n",
    "    # Genetic Algorithm: Evolutionary Process\n",
    "    def evolve(self):\n",
    "        best_tree = None\n",
    "        best_fitness = np.inf\n",
    "        take_over = False\n",
    "        # self.population.sort(key=lambda x: x.fitness) \n",
    "        #numpy sort of population over fitness\n",
    "        self.population.sort()\n",
    "        # print(f\"Initial best fitness: {self.population[0].fitness}\")\n",
    "        # print(f\"Initial best fitness: {self.population[1].fitness}\")\n",
    "        # print(f\"Initial best fitness: {self.population[2].fitness}\")\n",
    "        # print(f\"Initial worst fitness: {self.population[-1].fitness}\")\n",
    "\n",
    "        for generation in tqdm(range(self.max_generations)):\n",
    "            \n",
    "            if take_over:\n",
    "                # trasform the population in set and then back to list to remove duplicates\n",
    "                self.population = np.unique(self.population)\n",
    "                # sort the population based on fitness\n",
    "                self.population.sort()\n",
    "                self.population = self.population[:int(self.population_size*0.1)]\n",
    "                new_trees = np.array([Tree(\"grow\") for _ in range(int(self.population_size*0.3))]+[Tree(\"grow\") for _ in range(int(self.population_size*0.3))])\n",
    "                self.population=np.concatenate((self.population,new_trees))\n",
    "            \n",
    "            new_population=self.offspring_generation()\n",
    "\n",
    "            # for tree in new_population:\n",
    "            #     tree.compute_fitness()\n",
    "                \n",
    "            self.population=np.concatenate((self.population,new_population))\n",
    "            \n",
    "            generation_fitnesses = [tree.fitness for tree in self.population]\n",
    "            generation_best_fitness = min(generation_fitnesses)\n",
    "\n",
    "            if generation_best_fitness < best_fitness:\n",
    "                best_fitness = generation_best_fitness\n",
    "                best_tree = self.population[np.argmin(generation_fitnesses)]\n",
    "                self.best_fitness_history.append(best_fitness)\n",
    "            #trim the population to the best population_size\n",
    "            self.population.sort()\n",
    "            self.population = self.population[:self.population_size]\n",
    "            # print(f\"Generation {generation + 1}, Best Fitness: {best_fitness}\")\n",
    "            \n",
    "\n",
    "            n_best = [elem for elem in self.population if elem.fitness == self.population[0].fitness]\n",
    "            take_over = False\n",
    "            if len(n_best) > 0.9 * self.population_size:\n",
    "                    take_over = True\n",
    "                    # print(f\"Takeover at {generation} gen\")     \n",
    "            if(generation%1000==0):\n",
    "                print(f\"Generation {generation + 1}, Best Fitness: {best_fitness}, Best Formula: {best_tree.to_np_formula()}\")\n",
    "            if best_fitness <= 1e-33:\n",
    "                break   \n",
    "\n",
    "        return best_tree, best_fitness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem Definition and Symbolic Regression Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree depth:  3\n"
     ]
    }
   ],
   "source": [
    "POPULATION_SIZE = 1000\n",
    "MAX_GENERATIONS = 1000\n",
    "MUTATION_RATE = 0.1\n",
    "ELITISM_SIZE = 1\n",
    "GROW_FULL_RATIO = 1\n",
    "\n",
    "TREE_DEPTH = min(math.ceil(math.log(x_train.shape[0] + 1, 2)) + 2, 10)  # FIXME: temporary solution,IDK if it's good. (it's the depth to contain all the variables+1)\n",
    "print(\"Tree depth: \",TREE_DEPTH)\n",
    "\n",
    "VAR_NUM = x_train.shape[0]\n",
    "CONST_RANGE = 10 # Constats will be in the range [-CONST_RANGE, CONST_RANGE]\n",
    "\n",
    "Tree.set_params(unary_ops, binary_ops, VAR_NUM, 10, TREE_DEPTH, x_train_norm, y_train_norm, x_test_norm, y_test_norm)\n",
    "regressor = SymbolicRegression(\n",
    "    POPULATION_SIZE,\n",
    "    MAX_GENERATIONS,\n",
    "    MUTATION_RATE,\n",
    "    ELITISM_SIZE,\n",
    "    GROW_FULL_RATIO\n",
    "    #(x_train, y_train)   # per lexicase\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formula Revertion and Fitness Computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#UNCOMMENT TO PROFILE THE CODE (and comment the rest of the code)\n",
    "# cProfile.run(\"regressor.evolve()\",sort=\"tottime\") #for profiling so we can see the time taken by each function\n",
    "#the output will include the following columns:\n",
    "#tottime: Total time spent in the function (excluding time spent in other functions it calls).\n",
    "#cumtime: Cumulative time spent in the function (including time spent in sub-functions).\n",
    "def revert_formula(formula, x_stats, y_stats):\n",
    "    \"\"\"\n",
    "    Revert a formula from normalized space to original space for min-max normalization.\n",
    "\n",
    "    Parameters:\n",
    "        formula: str, symbolic regression formula in normalized space.\n",
    "        x_stats: dict, stats for input normalization (min, max).\n",
    "        y_stats: dict, stats for output normalization (min, max).\n",
    "\n",
    "    Returns:\n",
    "        str, formula in the original space.\n",
    "    \"\"\"\n",
    "    x_mins = x_stats[\"min\"].flatten()\n",
    "    x_maxs = x_stats[\"max\"].flatten()\n",
    "    y_min = y_stats[\"min\"]\n",
    "    y_max = y_stats[\"max\"]\n",
    "\n",
    "    # Wrap variables with normalization transformations\n",
    "    for i, (x_min, x_max) in enumerate(zip(x_mins, x_maxs)):\n",
    "        formula = formula.replace(\n",
    "            f\"x[{i}]\",\n",
    "            f\"(x[{i}] * ({x_max} - {x_min}) + {x_min})\"\n",
    "        )\n",
    "\n",
    "    # Apply the output transformation\n",
    "    reverted_formula = f\"(({formula}) * ({y_max} - {y_min})) + {y_min}\"\n",
    "    return reverted_formula\n",
    "\n",
    "def compute_fitness_from_formula(formula, x_data, y_data):\n",
    "    \"\"\"\n",
    "    Compute MSE fitness directly from a reverted formula.\n",
    "\n",
    "    Parameters:\n",
    "        formula: str, reverted symbolic regression formula.\n",
    "        x_data: np.ndarray, input data in original scale (variables, samples).\n",
    "        y_data: np.ndarray, true output data in original scale (samples).\n",
    "\n",
    "    Returns:\n",
    "        float, MSE fitness.\n",
    "    \"\"\"\n",
    "    # Convert the formula to a lambda function\n",
    "    eval_formula = eval(f\"lambda x: {formula}\", {\"np\": np})\n",
    "\n",
    "    # Compute predictions\n",
    "    y_pred = eval_formula(x_data)\n",
    "\n",
    "    # Calculate MSE\n",
    "    mse = np.mean(np.square(y_data - y_pred))\n",
    "    return mse "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithm Execution and Results Computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute the algorithm\n",
    "best_tree, best_fitness = regressor.evolve()    # FIX: high <= 0. There is a problem in mutate_subtree() after normalization?\n",
    "\n",
    "# Calculate the fitness on original data\n",
    "best_tree.compute_fitness(test=\"test\")\n",
    "\n",
    "# Revert the formula\n",
    "final_formula = best_tree.to_np_formula()\n",
    "reverted_formula = revert_formula(final_formula, x_stats, y_stats)\n",
    "print(f\"Reverted Formula:\\n{reverted_formula}\")\n",
    "\n",
    "print(f\"Test Fitness: {best_tree.fitness}\")\n",
    "print(f\"Train-Test Discrepancy: {best_fitness-best_tree.fitness}\")\n",
    "best_tree.compute_fitness(test=\"all\")\n",
    "print(f\"All Fitness: {best_tree.fitness}\")\n",
    "test_fitness_original=compute_fitness_from_formula(reverted_formula, x_test, y_test)\n",
    "print(f\"Test Fitness Original: {test_fitness_original}\")\n",
    "all_fitness_original=compute_fitness_from_formula(reverted_formula, x_train, y_train)\n",
    "print(f\"all Fitness Original: {all_fitness_original}\")\n",
    "\n",
    "#Print the best tree\n",
    "print(f\"Best Fitness History: {regressor.best_fitness_history}, changed {len(regressor.best_fitness_history)} times\")\n",
    "print(\"Best Tree:\")\n",
    "best_tree.add_drawing()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Tree Drawing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Collapse branches that can be simplified\n",
    "Tree.collapse_branch(best_tree.root,0,force_collapse=True)\n",
    "print(f\"Collapsed formula: {best_tree.to_np_formula()}\")\n",
    "print(\"Best Tree after collapsing:\")\n",
    "best_tree.add_drawing()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def test_formula(x):\n",
    "#     pass\n",
    "\n",
    "\n",
    "\n",
    "# x_tot=np.concatenate((x_train,x_test),axis=1)\n",
    "# y_tot=np.concatenate((y_train,y_test))\n",
    "# squared_errors = 0\n",
    "# for i in range(1):\n",
    "#     y_pred = test_formula(x_tot[:, i])\n",
    "                 \n",
    "#     squared_errors += np.square(y_tot[i] - y_pred) \n",
    "\n",
    "# print( squared_errors / x_tot.shape[1])\n",
    "   \n",
    "\n",
    "# def testing(tree):\n",
    "#    tree.compute_fitness()\n",
    "#    tree.compute_fitness2()\n",
    "\n",
    "# cProfile.run(\"testing(best_tree)\",sort=\"tottime\") #for profiling so we can see the time taken by each function\n",
    "\n",
    "\n",
    "# best_tree.compute_fitness()\n",
    "# print(best_tree.fitness)\n",
    "# best_tree.compute_fitness2()\n",
    "# print(best_tree.fitness)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CI2024",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
