{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from icecream import ic\n",
    "import cProfile \n",
    "import time\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get ariety of np.add\n",
    "np.maximum.nargs-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'divide': 'warn', 'over': 'warn', 'under': 'ignore', 'invalid': 'warn'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#warning settings\n",
    "np.seterr(all=\"ignore\") #ignore np warnings, the output will be nan or inf and will be handled correctly in the code. (using np.errstate slows down the code)\n",
    "# warnings.filterwarnings(\"ignore\", category=RuntimeWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "TRAIN_TEST_RATIO=0.3\n",
    "PROBLEM_NUMBER=8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the training and testing data\n",
    "def normalize_data(x, y, feature_range=(0, 1)):\n",
    "    \"\"\"\n",
    "    Normalize input (x) and output (y) data using min-max normalization.\n",
    "\n",
    "    Parameters:\n",
    "        x: np.ndarray, input data (variables, samples).\n",
    "        y: np.ndarray, output data (samples).\n",
    "        feature_range: tuple (min, max), range for normalization.\n",
    "\n",
    "    Returns:\n",
    "        x_norm: Min-max normalized input data.\n",
    "        y_norm: Min-max normalized output data.\n",
    "        x_stats: Dict containing min and max for x.\n",
    "        y_stats: Dict containing min and max for y.\n",
    "    \"\"\"\n",
    "    x_min = np.min(x, axis=1, keepdims=True)\n",
    "    x_max = np.max(x, axis=1, keepdims=True)\n",
    "    x_norm = (x - x_min) / (x_max - x_min) * (feature_range[1] - feature_range[0]) + feature_range[0]\n",
    "\n",
    "    y_min = np.min(y)\n",
    "    y_max = np.max(y)\n",
    "    y_norm = (y - y_min) / (y_max - y_min) * (feature_range[1] - feature_range[0]) + feature_range[0]\n",
    "\n",
    "    x_stats = {\"min\": x_min, \"max\": x_max}\n",
    "    y_stats = {\"min\": y_min, \"max\": y_max}\n",
    "\n",
    "    return x_norm, y_norm, x_stats, y_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading and Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem number: 8, variables: 6, train size: 15000, test size: 35000\n",
      "Training data: x shape (6, 15000), y shape (15000,)\n",
      "Testing data: x shape (6, 35000), y shape (35000,)\n"
     ]
    }
   ],
   "source": [
    "# Load problem data with context manager protocol\n",
    "with np.load(f'data/problem_{PROBLEM_NUMBER}.npz') as problem:\n",
    "    x_1 = problem['x']\n",
    "    y_1 = problem['y']\n",
    "\n",
    "# Shuffle the data\n",
    "permutation = np.random.permutation(len(y_1))\n",
    "x_1 = x_1[:, permutation]\n",
    "y_1 = y_1[permutation]\n",
    "\n",
    "# Determine train test split sizes\n",
    "problem_len=len(y_1)\n",
    "train_size=int(TRAIN_TEST_RATIO*problem_len)\n",
    "\n",
    "# Split data\n",
    "x_train = x_1[:, :train_size]\n",
    "y_train = y_1[:train_size]\n",
    "\n",
    "x_test = x_1[:, train_size:]\n",
    "y_test = y_1[train_size:]\n",
    "\n",
    "# Normalize training and testing data\n",
    "#FIXME: NORM\n",
    "# x_train_norm, y_train_norm, x_stats, y_stats = normalize_data(x_train, y_train)\n",
    "# x_test_norm, y_test_norm, _, _ = normalize_data(x_test, y_test)\n",
    "\n",
    "# To view the npz file, run python -m npzviewer \n",
    "# Print dataset information\n",
    "print(f\"Problem number: {PROBLEM_NUMBER}, variables: {x_1.shape[0]}, train size: {train_size}, test size: {problem_len-train_size}\")\n",
    "#FIXME: NORM\n",
    "# print(f\"Training data: x shape {x_train_norm.shape}, y shape {y_train_norm.shape}\")\n",
    "# print(f\"Testing data: x shape {x_test_norm.shape}, y shape {y_test_norm.shape}\")\n",
    "print(f\"Training data: x shape {x_train.shape}, y shape {y_train.shape}\")\n",
    "print(f\"Testing data: x shape {x_test.shape}, y shape {y_test.shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numpy functions definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "unary_ops = [\n",
    "    np.negative,\n",
    "    np.abs,\n",
    "    np.sqrt,\n",
    "    np.exp,\n",
    "    np.log,\n",
    "    np.sin,\n",
    "    np.cos,\n",
    "    np.tan,\n",
    "    np.arcsin,\n",
    "    np.arccos,\n",
    "    np.arctan,\n",
    "    np.sinh,\n",
    "    np.cosh,\n",
    "    np.tanh,\n",
    "    np.square,\n",
    "    np.cbrt,\n",
    "    np.reciprocal,\n",
    "    np.rint\n",
    "\n",
    "    # np.ceil,\n",
    "    # np.floor\n",
    "]\n",
    "\n",
    "binary_ops = [\n",
    "    np.add,\n",
    "    np.subtract,\n",
    "    np.multiply,\n",
    "    np.divide,\n",
    "    np.power,\n",
    "    np.maximum,\n",
    "    np.minimum,\n",
    "    np.mod\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Symbolic Regression Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tree import Tree\n",
    "\n",
    "class SymbolicRegression:\n",
    "    def __init__(self, population_per_island,island_num, max_generations, mutation_rate, elitism_size, grow_full_ratio,max_mutations,migration_rate,max_depth,spawn_depth,migration_interval):\n",
    "        self.population_per_island = population_per_island\n",
    "        self.island_num = island_num\n",
    "        self.max_generations = max_generations\n",
    "        self.mutation_rate = mutation_rate\n",
    "        self.elitism_size = elitism_size\n",
    "        self.grow_full_ratio = grow_full_ratio\n",
    "        self.max_mutations = max_mutations\n",
    "        self.unary_ops = unary_ops\n",
    "        self.binary_ops = binary_ops\n",
    "        self.migration_rate=migration_rate\n",
    "        self.best_fitness_history = []\n",
    "        self.migration_interval = migration_interval\n",
    "        #init np array  of size island_population\n",
    "        self.max_depth = max_depth\n",
    "        self.spawn_depth = spawn_depth\n",
    "        self.population = [None] * island_num\n",
    "        #DEPTH BASED (decomment every DEPTH BASED line):\n",
    "        # for j in range(island_num):\n",
    "        #     self.population[j] = np.array([\n",
    "        #         Tree(\"grow\",max_depth=max_depth+j,spawn_depth=spawn_depth+j) if i < int(population_per_island * self.grow_full_ratio) else Tree(\"full\",max_depth=max_depth+j,spawn_depth=spawn_depth+j) for i in range(population_per_island)\n",
    "        #     ])\n",
    "        for j in range(island_num):\n",
    "            self.population[j] = np.array([\n",
    "                Tree(\"grow\",max_depth=max_depth,spawn_depth=spawn_depth) if i < int(population_per_island * self.grow_full_ratio) else Tree(\"full\",max_depth=max_depth,spawn_depth=spawn_depth) for i in range(population_per_island)\n",
    "            ])\n",
    "         \n",
    "\n",
    "\n",
    "    # Parents selection methods\n",
    "    def select_parents_fitness_proportional(self, n_elems=2, epsilon=1e-10):\n",
    "        \"\"\"\n",
    "        Individuals with lower fitness have an higher probability to be selected.\n",
    "        Premature convergence if few individuals have significantly better fitness than others.\n",
    "        \"\"\"\n",
    "        fitnesses = [tree.fitness for tree in self.population]\n",
    "        inverted_fitnesses = [1 / (fitness + epsilon) for fitness in fitnesses]  # avoid division by zero\n",
    "        probabilities = inverted_fitnesses / sum(inverted_fitnesses)\n",
    "        parent1, parent2 = np.random.choice(self.population, size=n_elems, p=probabilities, replace=False)\n",
    "        return parent1, parent2\n",
    "    \n",
    "    def select_parents_lexicase(self):  # TODO: implement this\n",
    "        pass\n",
    "\n",
    "    def select_parents_rank_based(self, n_elems=2,island=0):\n",
    "        \"\"\"\n",
    "        Rank-based selection method.\n",
    "        Assigns probabilities based on inversed ranks instead of absolute fitness values.\n",
    "        \"\"\"\n",
    "        fitnesses = np.array([tree.fitness for tree in self.population[island]])\n",
    "        ranks = np.argsort(fitnesses)\n",
    "        inversed_ranks = len(fitnesses) - ranks\n",
    "        probabilities = inversed_ranks / np.sum(inversed_ranks)\n",
    "        return np.random.choice(self.population[island], n_elems, p=probabilities, replace=False)\n",
    "    \n",
    "    def select_parents_tournament(self,island=0):\n",
    "        tournament_size = 5\n",
    "        tournament = list(np.random.choice(self.population[island], tournament_size, replace=True))\n",
    "        tournament.sort(key=lambda x: x.fitness)\n",
    "        return tournament[0], tournament[1]\n",
    "    \n",
    "    def select_parents(self, island):\n",
    "        return self.select_parents_rank_based(island=island)\n",
    "\n",
    "    # Mutation methods\n",
    "    def mutate(self, tree):\n",
    "        if np.random.rand() < 0.5:\n",
    "            tree.mutate_subtree()\n",
    "        else:\n",
    "            mutations = np.random.randint(1, self.max_mutations+1)\n",
    "            tree.mutate_single_node(num_mutations=mutations)\n",
    "        \n",
    "        if np.random.rand() < 0.5:\n",
    "            #clone the tree and collapse the branch\n",
    "            tree_clone = tree.copy_tree()\n",
    "        \n",
    "            Tree.collapse_branch(tree_clone.root,force_collapse=True)\n",
    "            tree_clone.compute_fitness()\n",
    "            if(tree_clone.fitness is not None or tree_clone.fitness is not np.inf and tree_clone.fitness is not np.nan):\n",
    "                    tree = tree_clone\n",
    "\n",
    "\n",
    "    # Offsprings generation via mutation and crossover\n",
    "    def offspring_generation(self,island):\n",
    "        new_population = np.array([])\n",
    "\n",
    "        # Elitism   \n",
    "        elite_individuals = self.population[island][:self.elitism_size]\n",
    "        new_population = elite_individuals\n",
    "\n",
    "        # Main loop\n",
    "        while len(new_population) < self.population_per_island: #//2:\n",
    "            parent1, parent2 = self.select_parents(island=island)\n",
    "\n",
    "            # generate offsprings (one in mutation, two in crossover)\n",
    "            offsprings = np.array([])\n",
    "\n",
    "            if(np.random.rand() < self.mutation_rate):\n",
    "                parent_clone = parent1.copy_tree()\n",
    "                self.mutate(parent_clone)\n",
    "                # parent_clone.root.collapse_branch()\n",
    "                parent_clone.compute_fitness()\n",
    "                # if(parent_clone not in new_population):\n",
    "                offsprings = np.append(offsprings, [parent_clone])\n",
    "\n",
    "            else:    \n",
    "                offspring1, offspring2 = parent1.crossover(parent2)\n",
    "                if(offspring1 is not None or offspring2 is not None):\n",
    "                    # offspring1.root.collapse_branch()\n",
    "                    # offspring2.root.collapse_branch()\n",
    "            \n",
    "                    offspring1.compute_fitness()\n",
    "                    offspring2.compute_fitness()\n",
    "\n",
    "                    offsprings = np.append(offsprings, [offspring1, offspring2])\n",
    "\n",
    "            new_population = np.concatenate((new_population, offsprings))\n",
    "                \n",
    "        return new_population\n",
    "    \n",
    "    # Genetic Algorithm: Evolutionary Process\n",
    "    def evolve(self):\n",
    "        best_tree_island = np.full(self.island_num, None, dtype=object)\n",
    "        best_fitness_island = np.full(self.island_num, np.inf)\n",
    "        global_best_fitness = np.inf\n",
    "        global_best_tree = None\n",
    "        take_over = np.full(self.island_num, False)\n",
    "        # self.population_per_island.sort(key=lambda x: x.fitness) \n",
    "        #numpy sort of population over fitness\n",
    "        for i in range(self.island_num):\n",
    "            self.population[i].sort()\n",
    "      \n",
    "\n",
    "\n",
    "        for generation in tqdm(range(self.max_generations)):\n",
    "           \n",
    "            for i in range(self.island_num):\n",
    "                if take_over[i]:\n",
    "                    # print(f\"Takeover at {generation} gen on island {i} + {len(self.population[i])}\")\n",
    "                    # trasform the population in set and then back to list to remove duplicates\n",
    "                    self.population[i] = np.unique(self.population[i])\n",
    "                    # sort the population based on fitness\n",
    "                    self.population[i].sort()\n",
    "                    self.population[i] = self.population[i][:int(self.population_per_island*0.1)]\n",
    "                    #DEPTH BASED (decomment every DEPTH BASED line):\n",
    "                    # new_trees = np.array([Tree(\"grow\",max_depth=self.max_depth+i,spawn_depth=self.spawn_depth+i) for _ in range(int(self.population_per_island*0.9))])\n",
    "                    new_trees = np.array([Tree(\"grow\",max_depth=self.max_depth,spawn_depth=self.spawn_depth) for _ in range(int(self.population_per_island*0.9))])\n",
    "                    self.population[i]=np.concatenate((self.population[i],new_trees))\n",
    "                    self.population[i].sort()\n",
    "                \n",
    "                #DEPTH BASED (decomment every DEPTH BASED line):\n",
    "                # if np.random.rand()<self.migration_rate and i!=self.island_num-1:\n",
    "                #     #pick a random island to migrate to that is greater than the current island\n",
    "                #     island_to_migrate = np.random.randint(i+1,self.island_num)\n",
    "                #     #add self.population[i][0] to self.population[island_to_migrate]\n",
    "                #     self.population[island_to_migrate]=np.append(self.population[island_to_migrate],self.population[i][0])\n",
    "                #     print(f\"Migration at {generation} gen bewteen {i} and {island_to_migrate}\")\n",
    "                # if  self.island_num>1 and generation%self.migration_interval==0:\n",
    "                #     island_to_migrate = np.random.randint(0,self.island_num)\n",
    "                #     for _ in range(5):\n",
    "                #         #pick a random island to migrate to that is greater than the current island  \n",
    "                #         #select a random number from 0 to the population size of the current island\n",
    "                #         random_index = np.random.randint(0,len(self.population[i]))\n",
    "                #         #add self.population[i][random_index] to self.population[island_to_migrate]\n",
    "                #         self.population[island_to_migrate]=np.append(self.population[island_to_migrate],self.population[i][random_index])\n",
    "                #         #remove the tree from the current island\n",
    "                #         self.population[i]=np.delete(self.population[i],random_index)\n",
    "\n",
    "\n",
    "                if np.random.rand()<self.migration_rate and self.island_num>1:\n",
    "                    #pick a random island to migrate to that is greater than the current island\n",
    "                    island_to_migrate = np.random.randint(0,self.island_num)\n",
    "                    #select a random number from 0 to the population size of the current island\n",
    "                    random_index = np.random.randint(0,len(self.population[i]))\n",
    "                    #add self.population[i][random_index] to self.population[island_to_migrate]\n",
    "                    self.population[island_to_migrate]=np.append(self.population[island_to_migrate],self.population[i][random_index])\n",
    "                    #remove the tree from the current island\n",
    "                    self.population[i]=np.delete(self.population[i],random_index)\n",
    "                    \n",
    "\n",
    "\n",
    "                    print(f\"Migration at {generation} gen from {i} to {island_to_migrate}\")\n",
    "\n",
    "\n",
    "                new_population=self.offspring_generation(island=i)\n",
    "\n",
    "\n",
    "                # for tree in new_population:\n",
    "                #     tree.compute_fitness()\n",
    "                    \n",
    "                self.population[i]=np.concatenate((self.population[i],new_population))\n",
    "                self.population[i].sort()\n",
    "                \n",
    "                generation_best_fitness_island = self.population[i][0].fitness\n",
    "\n",
    "                if generation_best_fitness_island < best_fitness_island[i]:\n",
    "                    best_fitness_island[i] = generation_best_fitness_island\n",
    "                    best_tree_island[i] = self.population[i][0]\n",
    "                    self.best_fitness_history.append(best_fitness_island[i])\n",
    "\n",
    "                    if(best_fitness_island[i] < global_best_fitness):\n",
    "                        global_best_fitness = best_fitness_island[i]\n",
    "                        global_best_tree = best_tree_island[i]\n",
    "\n",
    "\n",
    "                #trim the population to the best island_population\n",
    "                \n",
    "                self.population[i] = self.population[i][:self.population_per_island]\n",
    "                # print(f\"Generation {generation + 1}, Best Fitness: {best_fitness}\")\n",
    "                \n",
    "\n",
    "                n_best = [elem for elem in self.population[i] if elem.fitness == self.population[i][0].fitness]\n",
    "                take_over[i] = False\n",
    "                if len(n_best) > 0.9 * self.population_per_island:\n",
    "                        take_over[i] = True\n",
    "                        # print(f\"Takeover at {generation} gen\")     \n",
    "                if(generation%50==0):\n",
    "                    print(f\"Generation {generation + 1}, Island: {i}, Best Fitness: {best_fitness_island[i]}, Best Formula: {best_tree_island[i].to_np_formula()}\")\n",
    "                # if best_fitness <= 1e-33:\n",
    "                #     break   \n",
    "\n",
    "        return global_best_tree, global_best_fitness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem Definition and Symbolic Regression Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ISLAND_POPULATION = 50\n",
    "ISLAND_NUM = 4\n",
    "MAX_GENERATIONS = 1000000\n",
    "MUTATION_RATE = 0.35\n",
    "ELITISM_SIZE = 0\n",
    "GROW_FULL_RATIO = 1\n",
    "\n",
    "TREE_MAX_DEPTH = 8\n",
    "TREE_SPAWN_DEPTH = 4 #the max depth at which the tree will be spawned, they can grow up to TREE_MAX_DEPTH\n",
    "\n",
    "\n",
    "VAR_NUM = x_train.shape[0]\n",
    "CONST_RANGE = 10 # Constats will be in the range [-CONST_RANGE, CONST_RANGE]\n",
    "MAX_MUTATIONS = 3  # Maximum number of mutations in a single mutation operation\n",
    "\n",
    "MIGRATION_RATE = 0.0025\n",
    "MIGRATION_INTERVAL = 100\n",
    "#FIXME: NORM\n",
    "# Tree.set_params(unary_ops, binary_ops, VAR_NUM, 10, TREE_DEPTH, x_train_norm, y_train_norm, x_test_norm, y_test_norm)\n",
    "\n",
    "Tree.set_params(unary_ops, binary_ops, VAR_NUM, CONST_RANGE, x_train, y_train, x_test, y_test)\n",
    "regressor = SymbolicRegression(\n",
    "    ISLAND_POPULATION,\n",
    "    ISLAND_NUM,\n",
    "    MAX_GENERATIONS,\n",
    "    MUTATION_RATE,\n",
    "    ELITISM_SIZE,\n",
    "    GROW_FULL_RATIO,\n",
    "    MAX_MUTATIONS,\n",
    "    MIGRATION_RATE,\n",
    "    TREE_MAX_DEPTH,\n",
    "    TREE_SPAWN_DEPTH,\n",
    "    MIGRATION_INTERVAL\n",
    "\n",
    "\n",
    "    #(x_train, y_train)   # per lexicase\n",
    ")\n",
    "#print the trees\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formula Revertion and Fitness Computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def revert_formula(formula, x_stats, y_stats):\n",
    "    \"\"\"\n",
    "    Revert a formula from normalized space to original space for min-max normalization.\n",
    "\n",
    "    Parameters:\n",
    "        formula: str, symbolic regression formula in normalized space.\n",
    "        x_stats: dict, stats for input normalization (min, max).\n",
    "        y_stats: dict, stats for output normalization (min, max).\n",
    "\n",
    "    Returns:\n",
    "        str, formula in the original space.\n",
    "    \"\"\"\n",
    "    x_mins = x_stats[\"min\"].flatten()\n",
    "    x_maxs = x_stats[\"max\"].flatten()\n",
    "    y_min = y_stats[\"min\"]\n",
    "    y_max = y_stats[\"max\"]\n",
    "\n",
    "    # Wrap variables with normalization transformations\n",
    "    for i, (x_min, x_max) in enumerate(zip(x_mins, x_maxs)):\n",
    "        formula = formula.replace(\n",
    "            f\"x[{i}]\",\n",
    "            f\"(x[{i}] * ({x_max} - {x_min}) + {x_min})\"\n",
    "        )\n",
    "\n",
    "    # Apply the output transformation\n",
    "    reverted_formula = f\"(({formula}) * ({y_max} - {y_min})) + {y_min}\"\n",
    "    return reverted_formula\n",
    "\n",
    "def compute_fitness_from_formula(formula, x_data, y_data):\n",
    "    \"\"\"\n",
    "    Compute MSE fitness directly from a reverted formula.\n",
    "\n",
    "    Parameters:\n",
    "        formula: str, reverted symbolic regression formula.\n",
    "        x_data: np.ndarray, input data in original scale (variables, samples).\n",
    "        y_data: np.ndarray, true output data in original scale (samples).\n",
    "\n",
    "    Returns:\n",
    "        float, MSE fitness.\n",
    "    \"\"\"\n",
    "    # Convert the formula to a lambda function\n",
    "    eval_formula = eval(f\"lambda x: {formula}\", {\"np\": np})\n",
    "\n",
    "    # Compute predictions\n",
    "    y_pred = eval_formula(x_data)\n",
    "\n",
    "    # Calculate MSE\n",
    "    mse = np.mean(np.square(y_data - y_pred))\n",
    "    return mse "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.4587669906486217e+45"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_fitness_from_formula(\"np.exp(np.square(np.multiply(np.multiply(-0.5453290513341242, -0.3559783504430727), np.add(np.multiply(np.multiply(x[1], x[0]), np.subtract(np.absolute(np.absolute(np.absolute(np.tan(-0.9144160900652034)))), np.sin(np.multiply(np.subtract(0.7048732443752681, np.multiply(x[1], x[0])), np.multiply(np.add(-1.933594769143653, -0.21950536092878314), np.remainder(0.058267655791954365, 1.6095452021540755)))))), np.multiply(np.subtract(np.multiply(np.divide(np.power(np.remainder(0.9409641151845616, 0.9850807896062177), np.power(0.9850807896062177, -0.9132639186362899)), np.power(np.power(0.9404743932099757, 1.3755139950965098), np.remainder(x[0], 0.17908034227130276))), np.power(np.power(np.power(0.9850807896062177, -0.5022007642052508), np.remainder(x[0], -0.5453290513341242)), np.multiply(np.add(x[1], -0.5453290513341242), x[0]))), np.absolute(np.arctan(np.arctan(np.subtract(x[0], x[1]))))), np.add(np.multiply(1.7743339625324417, np.add(np.tan(0.49803913145345025), np.power(np.power(0.9850807896062177, -1.789850963064198), np.remainder(-1.646242327114337, x[1])))), np.exp(np.add(np.power(np.power(0.9850807896062177, 1.996052865628402), np.remainder(x[0], 0.9659013507711744)), np.power(np.power(0.9404743932099757, 0.7304670270130629), np.subtract(x[0], x[1]))))))))))\", x_1, y_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithm Execution and Results Computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1000000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 1, Island: 0, Best Fitness: 22727151.51562162, Best Formula: np.minimum(np.remainder(3.2973580564360425, np.minimum(np.multiply(np.maximum(x[3], 9.281113742659958), -9.730299357375735), np.subtract(x[3], x[5]))), np.minimum(np.add(np.absolute(x[2]), np.maximum(x[0], 8.126520466931488)), np.sinh(np.minimum(x[1], x[4]))))\n",
      "Generation 1, Island: 1, Best Fitness: 22625602.41420725, Best Formula: np.minimum(np.exp(np.multiply(np.remainder(-4.0249076142693845, x[0]), np.remainder(x[5], x[3]))), np.multiply(np.add(np.minimum(x[1], 0.16785882097321192), np.sinh(x[4])), np.remainder(np.multiply(x[2], 0.25338359034583924), np.power(0.48378957079619767, -4.899731317858549))))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/1000000 [00:00<131:56:38,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 1, Island: 2, Best Fitness: 22772572.024617285, Best Formula: np.maximum(np.add(np.minimum(np.add(x[0], x[4]), np.remainder(-1.9384684228008116, 0.9240893598943227)), np.maximum(np.subtract(-1.016253887621673, x[1]), np.add(-6.984852550569438, x[2]))), np.maximum(np.minimum(np.multiply(6.216054392470209, 8.20262514449275), np.remainder(-3.7047930313362816, 5.394792909740877)), np.subtract(np.multiply(x[5], 5.108956508161187), np.multiply(x[3], 4.93306282505748))))\n",
      "Generation 1, Island: 3, Best Fitness: 22749332.166819897, Best Formula: np.maximum(np.add(np.minimum(np.minimum(x[4], x[1]), np.minimum(x[0], 4.818820427815266)), np.divide(np.subtract(0.1221795249009574, x[5]), np.reciprocal(-7.636419038302964))), np.maximum(np.multiply(np.divide(x[2], 9.298241653520108), x[3]), x[0]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/1000000 [00:01<175:49:57,  1.58it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 8\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#UNCOMMENT TO PROFILE THE CODE (and comment the rest of the code)\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# cProfile.run(\"regressor.evolve()\",sort=\"tottime\") #for profiling so we can see the time taken by each function\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m#the output will include the following columns:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      6\u001b[0m \n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Execute the algorithm\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m best_tree, best_fitness \u001b[38;5;241m=\u001b[39m \u001b[43mregressor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevolve\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m    \u001b[38;5;66;03m# FIX: high <= 0. There is a problem in mutate_subtree() after normalization?\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrain Fitness: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_fitness\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Calculate the fitness on original data\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[8], line 188\u001b[0m, in \u001b[0;36mSymbolicRegression.evolve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    181\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpopulation[i]\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mdelete(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpopulation[i],random_index)\n\u001b[0;32m    185\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMigration at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgeneration\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m gen from \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00misland_to_migrate\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 188\u001b[0m new_population\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moffspring_generation\u001b[49m\u001b[43m(\u001b[49m\u001b[43misland\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    191\u001b[0m \u001b[38;5;66;03m# for tree in new_population:\u001b[39;00m\n\u001b[0;32m    192\u001b[0m \u001b[38;5;66;03m#     tree.compute_fitness()\u001b[39;00m\n\u001b[0;32m    194\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpopulation[i]\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mconcatenate((\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpopulation[i],new_population))\n",
      "Cell \u001b[1;32mIn[8], line 105\u001b[0m, in \u001b[0;36mSymbolicRegression.offspring_generation\u001b[1;34m(self, island)\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmutate(parent_clone)\n\u001b[0;32m    104\u001b[0m \u001b[38;5;66;03m# parent_clone.root.collapse_branch()\u001b[39;00m\n\u001b[1;32m--> 105\u001b[0m \u001b[43mparent_clone\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_fitness\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    106\u001b[0m \u001b[38;5;66;03m# if(parent_clone not in new_population):\u001b[39;00m\n\u001b[0;32m    107\u001b[0m offsprings \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mappend(offsprings, [parent_clone])\n",
      "File \u001b[1;32mc:\\Users\\denni\\Desktop\\PythonStuff\\CompInt\\CI2024_Project\\tree.py:595\u001b[0m, in \u001b[0;36mTree.compute_fitness\u001b[1;34m(self, test)\u001b[0m\n\u001b[0;32m    592\u001b[0m eval_formula \u001b[38;5;241m=\u001b[39m \u001b[38;5;28meval\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlambda x: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mformula\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnp\u001b[39m\u001b[38;5;124m\"\u001b[39m: np, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnan\u001b[39m\u001b[38;5;124m\"\u001b[39m: np\u001b[38;5;241m.\u001b[39mnan, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minf\u001b[39m\u001b[38;5;124m\"\u001b[39m: np\u001b[38;5;241m.\u001b[39minf}) \n\u001b[0;32m    594\u001b[0m \u001b[38;5;66;03m# Exploiting np broadcasting\u001b[39;00m\n\u001b[1;32m--> 595\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43meval_formula\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_data\u001b[49m\u001b[43m)\u001b[49m  \n\u001b[0;32m    598\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39many(np\u001b[38;5;241m.\u001b[39misnan(y_pred)) \u001b[38;5;129;01mor\u001b[39;00m np\u001b[38;5;241m.\u001b[39many(np\u001b[38;5;241m.\u001b[39misinf(y_pred)):\n\u001b[0;32m    599\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfitness \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39minf\n",
      "File \u001b[1;32m<string>:1\u001b[0m, in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#UNCOMMENT TO PROFILE THE CODE (and comment the rest of the code)\n",
    "# cProfile.run(\"regressor.evolve()\",sort=\"tottime\") #for profiling so we can see the time taken by each function\n",
    "#the output will include the following columns:\n",
    "#tottime: Total time spent in the function (excluding time spent in other functions it calls).\n",
    "#cumtime: Cumulative time spent in the function (including time spent in sub-functions).\n",
    "\n",
    "# Execute the algorithm\n",
    "best_tree, best_fitness = regressor.evolve()    # FIX: high <= 0. There is a problem in mutate_subtree() after normalization?\n",
    "\n",
    "print(f\"Train Fitness: {best_fitness}\")\n",
    "# Calculate the fitness on original data\n",
    "best_tree.compute_fitness(test=\"test\")\n",
    "\n",
    "# Revert the formula\n",
    "final_formula = best_tree.to_np_formula()\n",
    "\n",
    "#FIXME: NORM\n",
    "# reverted_formula = revert_formula(final_formula, x_stats, y_stats)\n",
    "# print(f\"Reverted Formula:\\n{reverted_formula}\")\n",
    "\n",
    "print(f\"Test Fitness: {best_tree.fitness}\")\n",
    "print(f\"Train-Test Discrepancy: {best_fitness-best_tree.fitness}\")\n",
    "best_tree.compute_fitness(test=\"all\")\n",
    "print(f\"All Fitness: {best_tree.fitness}\")\n",
    "\n",
    "#FIXME: NORM\n",
    "# test_fitness_original=compute_fitness_from_formula(reverted_formula, x_test, y_test)\n",
    "# print(f\"Test Fitness Original: {test_fitness_original}\")\n",
    "# all_fitness_original=compute_fitness_from_formula(reverted_formula, x_train, y_train)\n",
    "# print(f\"all Fitness Original: {all_fitness_original}\")\n",
    "\n",
    "#Print the best tree\n",
    "print(f\"Best Fitness History: {regressor.best_fitness_history}, changed {len(regressor.best_fitness_history)} times\")\n",
    "print(\"Best Tree:\")\n",
    "best_tree.add_drawing()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Tree Drawing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Collapse branches that can be simplified\n",
    "Tree.collapse_branch(best_tree.root,0,force_collapse=True)\n",
    "print(f\"Collapsed formula: {best_tree.to_np_formula()}\")\n",
    "print(\"Best Tree after collapsing:\")\n",
    "best_tree.add_drawing()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = Tree(\"grow\",max_depth=TREE_MAX_DEPTH,spawn_depth=TREE_SPAWN_DEPTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "formula = tree.to_np_formula()\n",
    "tree2 = Tree.create_tree_from_np_formula(formula)\n",
    "# tree2.compute_fitness()\n",
    "# tree.compute_fitness()\n",
    "assert tree.to_np_formula() == tree2.to_np_formula()\n",
    "assert tree.fitness == tree2.fitness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def test_formula(x):\n",
    "#     pass\n",
    "\n",
    "\n",
    "\n",
    "# x_tot=np.concatenate((x_train,x_test),axis=1)\n",
    "# y_tot=np.concatenate((y_train,y_test))\n",
    "# squared_errors = 0\n",
    "# for i in range(1):\n",
    "#     y_pred = test_formula(x_tot[:, i])\n",
    "                 \n",
    "#     squared_errors += np.square(y_tot[i] - y_pred) \n",
    "\n",
    "# print( squared_errors / x_tot.shape[1])\n",
    "   \n",
    "\n",
    "# def testing(tree):\n",
    "#    tree.compute_fitness()\n",
    "#    tree.compute_fitness2()\n",
    "\n",
    "# cProfile.run(\"testing(best_tree)\",sort=\"tottime\") #for profiling so we can see the time taken by each function\n",
    "\n",
    "\n",
    "# best_tree.compute_fitness()\n",
    "# print(best_tree.fitness)\n",
    "# best_tree.compute_fitness2()\n",
    "# print(best_tree.fitness)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CI_24-25",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
